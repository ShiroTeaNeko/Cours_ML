{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection du churn - opérateur Télécom\n",
    "\n",
    "## Objectif\n",
    "Ce premier cas d'étude vous propose de découvrir la **classification binaire** et aborde des notions fondamentales du machine learning.\n",
    "\n",
    "Au cours de cette étude de cas, les principaux concepts abordés seront : \n",
    "* la classification binaire\n",
    "* la matrice de features\n",
    "* la cible d'un modèle\n",
    "* un modèle de machine learning\n",
    "* les arbres de décisions\n",
    "* la mesures de qualité du modèle : precision, rappel, accuracy, matrice de confusion\n",
    "* la courbe RoC\n",
    "* un algorithme plus complet : le ramdom-forest \n",
    "\n",
    "\n",
    "Prérequis\n",
    "* dataset TelcoChurnDetection\n",
    "\n",
    "## Contexte\n",
    "Vous êtes datascientist pour un opérateur télécom. Le département Marketing vous demande votre aide afin de cibler les clients qui sont insatisfaits et risque de résilier prochainement leur abonnement. Le ciblage de ces clients a pour objectif de leur proposer des offres promotionnels pour les conserver plus longtemps.\n",
    "Vous décidez alors de mettre en place un modèle de prédiction du churn à partir des données de la base client.\n",
    "\n",
    "*Churn* = attrition, départ des clients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Le dataset que vous avez à disposition contient les informations suivantes : \n",
    "* customerID - customer id\n",
    "* gender - client gender (male / female)\n",
    "* SeniorCitizen - is the client retired (1, 0)\n",
    "* Partner - is the client married (Yes, No)\n",
    "* tenure - how many months a person has been a client of the company\n",
    "* PhoneService - is the telephone service connected (Yes, No)\n",
    "* MultipleLines - are multiple phone lines connected (Yes, No, No phone service)\n",
    "* InternetService - client's Internet service provider (DSL, Fiber optic, No)\n",
    "* OnlineSecurity - is the online security service connected (Yes, No, No internet service)\n",
    "* OnlineBackup - is the online backup service activated (Yes, No, No internet service)\n",
    "* DeviceProtection - does the client have equipment insurance (Yes, No, No internet service)\n",
    "* TechSupport - is the technical support service connected (Yes, No, No internet service)\n",
    "* StreamingTV - is the streaming TV service connected (Yes, No, No internet service)\n",
    "* StreamingMovies - is the streaming cinema service activated (Yes, No, No internet service)\n",
    "* Contract - type of customer contract (Month-to-month, One year, Two year)\n",
    "* PaperlessBilling - whether the client uses paperless billing (Yes, No)\n",
    "* PaymentMethod - payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
    "* MonthlyCharges - current monthly payment\n",
    "* TotalCharges - the total amount that the client paid for the services for the entire time\n",
    "* Churn - whether there was a churn (Yes or No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture du jeux de données et exploration \n",
    "\n",
    "Le jeu de données est constitué d'un fichier CSV qui peut être lu directement dans un Dataframe pandas.\n",
    "\n",
    "Les quelques lignes suivantes permettent la lecture du dataset et une première exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "# Set here the path to the dataset on your machine\n",
    "dataset_path = \"./datasets/TelcoChurnDetection/telecom_users.csv\"\n",
    "dataset = pd.read_csv(dataset_path, index_col=0)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed conversion\n",
    "dataset.TotalCharges = pd.to_numeric(dataset.TotalCharges, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour entraîner un modèle, il faut des données.\n",
    "\n",
    "Les données sont généralement représentées sous forme de matrice (en mathématiques) / dataframe (en python).\n",
    "\n",
    "Chaque **ligne** de la matrice est une \"observation\".\n",
    "\n",
    "ici : **une ligne = un client**\n",
    "\n",
    "Nb : dans la \"vraie vie\", il faut souvent beaucoup de travail avant de parvenir à cette matrice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print one row ; uncomment one of the folowing line\n",
    "# dataset.iloc[0]\n",
    "# dataset.iloc[0, :]\n",
    "# dataset.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here check that there is one row per customer\n",
    "# Hint: checkout documentation for 'value_counts'\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque **colonne** de la matrice est une \"caractéristique\", ou \"variable explicative\", ou encore \"feature\".\n",
    "\n",
    "Combien de features avons-nous ici ? Pouvez-vous les lister ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here list the avaiable customer features and show which are numerical features\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une colonne est particulière, il s'agit de la **cible** (**target**).\n",
    "\n",
    "Dans notre contexte il s'agit du *churn*.\n",
    "\n",
    "**L'objectif du machine learning est de faire des prédictions, donc de prédire le churn avant qu'il ne se produise, sachant certaines variables explicatives**.\n",
    "\n",
    "Il faut donc distinguer :\n",
    "* les variables explicatives qui sont *connues* au moment de l'inférence\n",
    "* la variable à prédire qui est *inconnue*\n",
    "\n",
    "Dans la cellule suivante, on sépare l'ensemble des features (données connues) 'X' et la cible 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = NotImplementedError()\n",
    "\n",
    "# target\n",
    "y = NotImplementedError()\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données\n",
    "\n",
    "Dans les cellules suivantes, on cherche à bien comprendre ce que contient le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher ici la répartition de la cible (bar)\n",
    "dataset.groupby(\"???\")\\\n",
    "    .size()\\\n",
    "    .plot(kind=\"???\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturellement, on souhaite comprendre le contenu des variables explicatives et le lien entre les variables et la cible.\n",
    "\n",
    "On commence par regarder les 2 variables numériques :\n",
    "* *tenure* : l'ancienneté du client\n",
    "* *MonthlyCharges* : charge mensuelles.\n",
    "\n",
    "Pour chacune d'elle, on dessine : \n",
    "- la distribution (histogramme ou courbe de densité)\n",
    "- la corrélation avec la cible\n",
    "\n",
    "Avant cela, on suggère de transformer la cible en variable numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show correlation with target, you need a numerical column. \n",
    "# Apply the following function to the entire columns\n",
    "\n",
    "def transform_to_binary(val):\n",
    "    \"\"\"\n",
    "    val is equal to \"Yes\" or \"No\"\n",
    "    This function should return 0 or 1\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "dataset.Churn = ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print here distribution and correlation with target\n",
    "# hint: Have a look on notebook 0 : how to print pairwise correlations\n",
    "\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables catégorielles\n",
    "\n",
    "Maintenant que nous avons vu l'influence de la durée de rétention et des charges mensuelles, nous allons nous penchez sur les 3 variables suivantes :\n",
    "* *SeniorCitizen* \n",
    "* *Partner*\n",
    "* *Dependents*\n",
    "\n",
    "Aide pour afficher : https://seaborn.pydata.org/tutorial/categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here plot relations between categorical feature and target\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permier modèle de Machine Learning : un arbre de décision\n",
    "\n",
    "Il s'agit d'un modèle qu'on peut facilement se représenter : l'algorithme construit un arbre de décision, qui correspondent à l'enchaînement de plusieurs décisions de type : \"SI .... ALORS....\".\n",
    "Par exemple : \n",
    "\n",
    "#### Arbre de décision avec un seul niveau (une règle)\n",
    "\"SI montlyCharges > 30 ALORS CHURN\"\n",
    "\n",
    "#### Arbre de décision avec 2 niveaux\n",
    "* SI montlyCharges > 30 ALORS\n",
    "    * ET SI tenure < 10 ALORS CHURN\n",
    "    * SINON : NON CHURN\n",
    "* SINON : NON CHURN\n",
    "\n",
    "\n",
    "On distingue 2 phases : \n",
    "* l'**apprentissage** (*fit*) : l'algorithme de machine learning va *construire un modèle* à partir des données. Pour les arbres de décision, cela signifie créer les règles : choisir à la fois les *variables* de décision et les *seuils*. A la fin de l'apprentissage, on obtient un modèle, c'est à dire un ensemble de règles et de seuils permettant de *prédire* la cible.\n",
    "\n",
    "* la **prédiction** : c'est lorsqu'on utilise le modèle pour effectuer des prédictions. Il s'agit d'appliquer les règles apprises par l'algorithme.\n",
    "\n",
    "\n",
    "Si la phase d'apprentissage peut être (très) longue, la prédiction est généralement instantanée.\n",
    "\n",
    "\n",
    "Dans les lignes suivantes, on charge, entraîne un modèle de machine learning et on l'utilise.\n",
    "\n",
    "La première chose à faire est de mettre le dataset dans le bon format. Ce qui signifie :\n",
    "* Sélection de variables\n",
    "* Avoir valeurs uniquement numériques (nécessaire en général même si certains algorithmes comme les arbres de décisions ne le nécessitent pas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection de variables & formatting\n",
    "On utilise les variables observées au dessus : \n",
    "* MonthlyCharges\n",
    "* tenure\n",
    "* TotalCharges\n",
    "* seniorCitizen\n",
    "* Partner\n",
    "* Dependants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ???\n",
    "X = X[features].copy() # copy here to not have a slice and suppress warning\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to transform categorical value\n",
    "categorical_features = ???\n",
    "for feature in categorical_features:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "y = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du modèle et entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Et voilà !!\n",
    "\n",
    "\n",
    "Pour bien illustrer le modèle, nous allons voir ce qu'il y a à l'intérieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# WARNING: Do not plot deep tree (5 is deep... but only for plotting)\n",
    "\n",
    "# plot_tree(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation du modèle\n",
    "\n",
    "\n",
    "**Comment savoir quelle est la qualité de la prédiction ?**\n",
    "\n",
    "Est-ce que le modèle se trompe ?\n",
    "\n",
    "Pour cela nous allons calculer les mesures suivantes :\n",
    "* la précision (*precision*) : parmis les personnes prédictes CHURN, combien le sont réellement ? \n",
    "* le rappel (*recall*) : parmis les personnes qui sont CHURN, combien ont été correctement prédites ?\n",
    "* l'exactitude (*accuracy*) : combien de personnes sont correctement prédites.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here compute true positif, false positif, false negative\n",
    "TP = ((y_pred == 1) & (y_pred == y_true)).sum()\n",
    "FP = ???\n",
    "FN = ???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then compute precision, recall and accuracy\n",
    "precision = TP / (TP + FN)\n",
    "recall = ???\n",
    "accuracy = ???\n",
    "\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compromis Precision - Recall\n",
    "\n",
    "\n",
    "Est-ce qu'il faut mieux plus de précision et moins de recall, ou moins de précision et plus de recall ?\n",
    "\n",
    "A performance de modèle égal, une augmentation de la précision se fait au détriment du recall, et inversement.\n",
    "\n",
    "Les prochaines cellules illustrent ce compromis entre performance et recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thr = precision_recall_curve(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(thr, precision[:-1], label=\"precision\")\n",
    "plt.plot(thr, recall[:-1], label=\"recall\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr, tpr, thr = roc_curve(y_true, y_pred_proba)\n",
    "auc = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"ROC (auc={auc:.3f})\")\n",
    "plt.plot([0,1], [0,1], label=\"Random model\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarques : \n",
    "* Les courbes de précision et de recall ont un sens \"métier\", utiles pour une analyse qualitative du modèle.\n",
    "* la courbe ROC est difficile à interprêter. Il s'agit avant tout d'un moyen de **comparaison des modèles** (savoir si un modèle est meilleur qu'un autre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un algorithme puissant : les forêts aléatoires (RandomForest)\n",
    "\n",
    "Cet algorithme relativement simple offre de très belles performances dans de nombreux problèmes. C'est en quelques sorte un algorithme \"couteau-suisse\".\n",
    "\n",
    "Cet algorithme est en fait basé sur les arbres de décisions. Mais plutôt que d'utiliser un seul arbre, il va en utiliser de nombreux, et essayant d'avoir de légère différences entre chaque arbre.\n",
    "La prédiction finale est faite en aggrégeant les prédictions de chaque arbre, par exemple par un vote de chaque arbre.\n",
    "\n",
    "Dans les cellules suivantes on charge le nouveau modèle et on se propose de comparer les performances du nouveau modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new predictions\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with RandomForest\n",
    "\n",
    "fpr2, tpr2, thr2 = roc_curve(y_true, y_pred_proba)\n",
    "auc2 = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"1Tree (auc={auc:.3f})\")\n",
    "plt.plot(fpr2, tpr2, label=f\"RF (auc={auc2:.3f})\")\n",
    "plt.plot([0,1], [0,1], label=\"Random model\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Nous avons maintenant un second algorithme dans notre boîte à outil, afin d'adresser les problèmes de **classification binaire**.\n",
    "Avec ces 2 algorithmes, nous avons mis au point 2 modèles pour répondre à notre problèmatique de churn.\n",
    "\n",
    "Beaucoup de choses peuvent cependant être améliorées ! N'hésitez pas à revenir sur ce notebook plus tard pour tenter d'améliorer le modèle.\n",
    "\n",
    "Nous allons voir en particulier dans la suite comment rendre les modèles plus robustes et plus performants.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
