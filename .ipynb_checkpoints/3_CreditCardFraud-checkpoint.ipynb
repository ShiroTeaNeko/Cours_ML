{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection de fraud au payement\n",
    "\n",
    "Ce jeu de données vous propose un nouveau problème de classification binaire : décider si un payement est une FRAUDE ou non.\n",
    "\n",
    "### Objectifs \n",
    "* Récapituler les notions vues jusqu'à présent : classification binaire, validation, mesure de performance, hyper-optimisation.\n",
    "* Découvrir une nouvelle famille d'algorithmes : les boosting trees\n",
    "* Appréhender un problème de classification bianaire \"déséquilibré\"\n",
    "\n",
    "Ce notebook va réutiliser les concepts déjà vu jusqu'à présent. Il contient moins de code et vous laisse plus libre dans l'implémentation. Réutilisez le code des notebooks précédents !\n",
    "\n",
    "### Contexte \n",
    "Vous travaillez en tant que *Machine Learning Engineer* pour une **banque**. Les équipes de lutte contre la fraude souhaîte mettre en place un **algorithme pour arrêter la fraude** en temps réel : l'algorithme doit être capable de détecter si un virement est frauduleux ou non afin de le bloquer.\n",
    "\n",
    "A partir d'un jeu de données qu'on vous fournit, il vous est demandé de mettre en place un tel algorithme. Dans ce jeu, un certain nombre de virements frauduleux a été préalablement détecté.\n",
    "\n",
    "L'analyse des performances d'un tel algorithme permettra de décider de la mise en place ou non d'un tel moteur de détection en temps réel, qui se basera sur votre algorithme.\n",
    "\n",
    "Par ailleurs, un de vos collègues a mis en place 2 modèles de détection auxquels il va falloir vous comparer.\n",
    "\n",
    "\n",
    "(faire le coup de la fonction qui renvoie 0, ou 1 aléatoirement !! Montrer que courbe ROC pas fou, et montrer d'autres mesures.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle de comparaison\n",
    "\n",
    "Les 2 modèles suivants sont des modèles \"naïf\" de détection de fraude. Serez-vous capable d'obtenir un meilleur modèle ?\n",
    "\n",
    "Ces modèles s'utilisent de la même manière que les modèles vus précédemment : ils ont une méthode _fit_ pour l'entraînement et _predict_ ou _predict_proba_ pour la prédiction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "\n",
    "class RandomFraudDetector:\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        assert 0 <= p <= 1\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = self.predict_proba(X)\n",
    "        return scores > 0.5 \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        scores =  self.p * 2 * np.random.rand(X.shape[0])\n",
    "        scores[scores<0] = 0\n",
    "        scores[scores>1] = 1\n",
    "        return scores\n",
    "\n",
    "randomFraudDetector = RandomFraudDetector(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "class NaiveFraudDetector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.zeros((X.shape[0],)) \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.zeros((X.shape[0],))\n",
    "\n",
    "naiveFraudDetector = NaiveFraudDetector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture du dataset\n",
    "\n",
    "Dans cette première section :\n",
    "* Lecture du dataset\n",
    "* Quelle est la cible ? Quelles sont les features exploitables ?\n",
    "* Effectuer quelques visualisation\n",
    "  * Quelle est la durée pendant laquelle les données ont été collectées ?\n",
    "  * Est-ce que les fraudes sont réparties dans le temps ?\n",
    "  * Quel est le montant des transactions en général et des fraudes en particulier ?\n",
    "\n",
    "Les colonnes du jeu de données sont : \n",
    "* _Class_ : est-ce que c'est une fraude ?\n",
    "* _Time_ : moment de la transaction\n",
    "* _Amount_ : montant de la transaction\n",
    "* _V1_ à _V28_ : des features numériques anonymisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142645</th>\n",
       "      <td>163942.0</td>\n",
       "      <td>-1.019203</td>\n",
       "      <td>0.481492</td>\n",
       "      <td>2.274583</td>\n",
       "      <td>4.241325</td>\n",
       "      <td>1.574835</td>\n",
       "      <td>1.261159</td>\n",
       "      <td>-0.642177</td>\n",
       "      <td>0.504488</td>\n",
       "      <td>-2.209828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.633903</td>\n",
       "      <td>-0.249594</td>\n",
       "      <td>0.219320</td>\n",
       "      <td>0.270599</td>\n",
       "      <td>0.546483</td>\n",
       "      <td>0.083095</td>\n",
       "      <td>0.110002</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142646</th>\n",
       "      <td>63899.0</td>\n",
       "      <td>-0.370668</td>\n",
       "      <td>0.988509</td>\n",
       "      <td>2.608039</td>\n",
       "      <td>2.110778</td>\n",
       "      <td>-0.256008</td>\n",
       "      <td>0.272036</td>\n",
       "      <td>0.118741</td>\n",
       "      <td>0.193841</td>\n",
       "      <td>-0.587576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>0.146565</td>\n",
       "      <td>-0.123053</td>\n",
       "      <td>0.406696</td>\n",
       "      <td>-0.110622</td>\n",
       "      <td>-0.087303</td>\n",
       "      <td>0.074957</td>\n",
       "      <td>0.044112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142647</th>\n",
       "      <td>41231.0</td>\n",
       "      <td>-0.428687</td>\n",
       "      <td>0.948979</td>\n",
       "      <td>1.287959</td>\n",
       "      <td>-0.028794</td>\n",
       "      <td>0.032788</td>\n",
       "      <td>-0.698476</td>\n",
       "      <td>0.539625</td>\n",
       "      <td>0.126356</td>\n",
       "      <td>-0.518914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214565</td>\n",
       "      <td>-0.653256</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.252761</td>\n",
       "      <td>-0.215620</td>\n",
       "      <td>0.057347</td>\n",
       "      <td>0.231959</td>\n",
       "      <td>0.087622</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142648</th>\n",
       "      <td>35059.0</td>\n",
       "      <td>-1.075405</td>\n",
       "      <td>1.338826</td>\n",
       "      <td>0.117071</td>\n",
       "      <td>-0.204691</td>\n",
       "      <td>-0.524877</td>\n",
       "      <td>-1.261053</td>\n",
       "      <td>0.435116</td>\n",
       "      <td>0.439694</td>\n",
       "      <td>-1.098636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151833</td>\n",
       "      <td>-0.721981</td>\n",
       "      <td>0.147504</td>\n",
       "      <td>0.459192</td>\n",
       "      <td>-0.685286</td>\n",
       "      <td>0.718542</td>\n",
       "      <td>-0.275357</td>\n",
       "      <td>-0.044909</td>\n",
       "      <td>53.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142649</th>\n",
       "      <td>166543.0</td>\n",
       "      <td>0.057775</td>\n",
       "      <td>0.894337</td>\n",
       "      <td>0.242284</td>\n",
       "      <td>-0.624382</td>\n",
       "      <td>0.516993</td>\n",
       "      <td>-1.035741</td>\n",
       "      <td>1.027803</td>\n",
       "      <td>-0.218657</td>\n",
       "      <td>-0.089848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267035</td>\n",
       "      <td>-0.567926</td>\n",
       "      <td>0.042612</td>\n",
       "      <td>-0.106862</td>\n",
       "      <td>-0.457732</td>\n",
       "      <td>0.146251</td>\n",
       "      <td>0.250059</td>\n",
       "      <td>0.096590</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142650 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0          406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "1          472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "2         4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "3         6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "4         7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "142645  163942.0 -1.019203  0.481492  2.274583  4.241325  1.574835  1.261159   \n",
       "142646   63899.0 -0.370668  0.988509  2.608039  2.110778 -0.256008  0.272036   \n",
       "142647   41231.0 -0.428687  0.948979  1.287959 -0.028794  0.032788 -0.698476   \n",
       "142648   35059.0 -1.075405  1.338826  0.117071 -0.204691 -0.524877 -1.261053   \n",
       "142649  166543.0  0.057775  0.894337  0.242284 -0.624382  0.516993 -1.035741   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0      -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "1       0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "2       0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "3      -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "4       1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "142645 -0.642177  0.504488 -2.209828  ...  0.310800  0.633903 -0.249594   \n",
       "142646  0.118741  0.193841 -0.587576  ... -0.002159  0.146565 -0.123053   \n",
       "142647  0.539625  0.126356 -0.518914  ... -0.214565 -0.653256  0.008115   \n",
       "142648  0.435116  0.439694 -1.098636  ... -0.151833 -0.721981  0.147504   \n",
       "142649  1.027803 -0.218657 -0.089848  ... -0.267035 -0.567926  0.042612   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "0       0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "1      -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "2      -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "3      -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "4      -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "142645  0.219320  0.270599  0.546483  0.083095  0.110002    0.76      0  \n",
       "142646  0.406696 -0.110622 -0.087303  0.074957  0.044112    0.00      0  \n",
       "142647  0.252761 -0.215620  0.057347  0.231959  0.087622    9.99      0  \n",
       "142648  0.459192 -0.685286  0.718542 -0.275357 -0.044909   53.80      0  \n",
       "142649 -0.106862 -0.457732  0.146251  0.250059  0.096590    1.29      0  \n",
       "\n",
       "[142650 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"./datasets/CreditCardFraud_short.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premiers modèles\n",
    "\n",
    "Dans cette partie, il vous est demandé :\n",
    "* d'effectuer un premier modèle à partir d'un randomForest. Quelle est la meilleure précision que vous pouvez atteindre ?\n",
    "* comparer ce score avec le score des modèles naïfs.\n",
    "\n",
    "Qu'en pensez-vous ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle Boosting Tree\n",
    "\n",
    "On a utilisé précédemment le random Forest. L'algorithme se base sur les arbres de décisions. La stratégie de l'algorithme consiste à utiliser un grand nombre d'estimateurs (les arbres) qui ont tendance à overfitté individuellement, mais collectivement le comportement sera beaucoup moins variables (des tirages aléatoires permettant d'avoir des arbres toujours légèrement différents.)\n",
    "\n",
    "\n",
    "Les Boosting Tree partent sur une autre stratégie : l'idée est d'utiliser une série d'arbre, construit successivement, dont chacun va tenter de réduire l'erreur d'estimation des précédents arbres.\n",
    "\n",
    "En comparaison :\n",
    "* Random Forest : minimisation de la variance en construisant des arbres aléatoires et indépendant\n",
    "* Boosting Tree : minimisation du biais en construisant successivement des arbres liés entre eux\n",
    "\n",
    "Il existe plusieurs implémentations avec des différences.\n",
    "Dans le package scikit-learn : Gradient Boosting Tree & AdaBoost.\n",
    "\n",
    "Exceptionnellement nous allons utiliser un algorithme d'un autre package, mais qui est très populaire : **xgboost**\n",
    "\n",
    "Voir la documentation : https://xgboost.readthedocs.io/en/latest/get_started.html\n",
    "\n",
    "La ligne suivante permet de vérifier que le package est bien installé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite, nous vous proposer de créer un modèle xgboost et de l'évaluer. Est-ce que le résultat est meilleur ou moins bon ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rééquilibrage des classes\n",
    "\n",
    "\n",
    "Dans le cas comme ici avec un grand déséquilibre entre les classes, une technique courante et de les rééquilibrer. Il existe plusieurs possibilités, par exemple : \n",
    "* Supprimer des observations de la classe trop représentée pour avoir une partié correcte\n",
    "* Générer des éléments de la classe sous-représentés à partir des éléments existants\n",
    "\n",
    "Pouvez-vous essayer l'une ou l'autre de ces approches ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
